{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-04-09T08:21:04.490920Z","iopub.execute_input":"2023-04-09T08:21:04.491351Z","iopub.status.idle":"2023-04-09T08:21:12.082363Z","shell.execute_reply.started":"2023-04-09T08:21:04.491311Z","shell.execute_reply":"2023-04-09T08:21:12.081098Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"print(\"Version of Tensorflow: \", tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T08:21:12.085503Z","iopub.execute_input":"2023-04-09T08:21:12.086795Z","iopub.status.idle":"2023-04-09T08:21:12.093835Z","shell.execute_reply.started":"2023-04-09T08:21:12.086739Z","shell.execute_reply":"2023-04-09T08:21:12.092603Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Version of Tensorflow:  2.11.0\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Cuda Availability: \", tf.test.is_built_with_cuda())","metadata":{"execution":{"iopub.status.busy":"2023-04-09T08:21:12.095495Z","iopub.execute_input":"2023-04-09T08:21:12.097073Z","iopub.status.idle":"2023-04-09T08:21:12.107450Z","shell.execute_reply.started":"2023-04-09T08:21:12.097028Z","shell.execute_reply":"2023-04-09T08:21:12.106268Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Cuda Availability:  True\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"GPU  Availability: \", tf.test.is_gpu_available())","metadata":{"execution":{"iopub.status.busy":"2023-04-09T08:21:12.110162Z","iopub.execute_input":"2023-04-09T08:21:12.110478Z","iopub.status.idle":"2023-04-09T08:21:14.264609Z","shell.execute_reply.started":"2023-04-09T08:21:12.110450Z","shell.execute_reply":"2023-04-09T08:21:14.263488Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"GPU  Availability:  True\n","output_type":"stream"}]},{"cell_type":"code","source":"tf.config.list_physical_devices('GPU')","metadata":{"execution":{"iopub.status.busy":"2023-04-09T08:21:21.848907Z","iopub.execute_input":"2023-04-09T08:21:21.849276Z","iopub.status.idle":"2023-04-09T08:21:21.861112Z","shell.execute_reply.started":"2023-04-09T08:21:21.849244Z","shell.execute_reply":"2023-04-09T08:21:21.859986Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"},"metadata":{}}]},{"cell_type":"code","source":"# Check nos of GPUS\n\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))","metadata":{"execution":{"iopub.status.busy":"2023-04-09T08:21:24.337213Z","iopub.execute_input":"2023-04-09T08:21:24.337589Z","iopub.status.idle":"2023-04-09T08:21:24.343416Z","shell.execute_reply.started":"2023-04-09T08:21:24.337557Z","shell.execute_reply":"2023-04-09T08:21:24.342184Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Num GPUs Available:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Set the seed value\nseed = 123","metadata":{"execution":{"iopub.status.busy":"2023-04-09T08:21:29.915073Z","iopub.execute_input":"2023-04-09T08:21:29.915632Z","iopub.status.idle":"2023-04-09T08:21:29.921656Z","shell.execute_reply.started":"2023-04-09T08:21:29.915588Z","shell.execute_reply":"2023-04-09T08:21:29.920606Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/515k-hotel-reviews-data-in-europe/Hotel_Reviews.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-09T08:21:54.452899Z","iopub.execute_input":"2023-04-09T08:21:54.453269Z","iopub.status.idle":"2023-04-09T08:22:00.217976Z","shell.execute_reply.started":"2023-04-09T08:21:54.453229Z","shell.execute_reply":"2023-04-09T08:22:00.216527Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Create a new dataframe with only the Positive_Review and Negative_Review columns\ndf_train = df[[\"Positive_Review\", \"Negative_Review\"]]\n\n# Use the melt function to stack the Positive_Review and Negative_Review columns on top of each other\ndf_train = df_train.melt(var_name=\"Sentiment\", value_name=\"Text\")\n\n# Map the Sentiment column to 1 for Positive_Review and 0 for Negative_Review\ndf_train[\"Sentiment\"] = df_train[\"Sentiment\"].map({\"Positive_Review\": 1, \"Negative_Review\": 0})\n\n# Drop any rows with empty or missing Text\ndf_train = df_train.dropna(subset=[\"Text\"])\n\n# Reset the index of the dataframe\ndf_train = df_train.reset_index(drop=True)\n\ndf_train[\"ID\"] = df_train.index\ndf_train","metadata":{"execution":{"iopub.status.busy":"2023-04-09T08:22:07.536013Z","iopub.execute_input":"2023-04-09T08:22:07.536574Z","iopub.status.idle":"2023-04-09T08:22:07.904736Z","shell.execute_reply.started":"2023-04-09T08:22:07.536510Z","shell.execute_reply":"2023-04-09T08:22:07.903775Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"         Sentiment                                               Text       ID\n0                1   Only the park outside of the hotel was beauti...        0\n1                1   No real complaints the hotel was great great ...        1\n2                1   Location was good and staff were ok It is cut...        2\n3                1   Great location in nice surroundings the bar a...        3\n4                1    Amazing location and building Romantic setting         4\n...            ...                                                ...      ...\n1031471          0   no trolly or staff to help you take the lugga...  1031471\n1031472          0           The hotel looks like 3 but surely not 4   1031472\n1031473          0   The ac was useless It was a hot week in vienn...  1031473\n1031474          0                                        No Negative  1031474\n1031475          0       I was in 3rd floor It didn t work Free Wife   1031475\n\n[1031476 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentiment</th>\n      <th>Text</th>\n      <th>ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Only the park outside of the hotel was beauti...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>No real complaints the hotel was great great ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Location was good and staff were ok It is cut...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Great location in nice surroundings the bar a...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Amazing location and building Romantic setting</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1031471</th>\n      <td>0</td>\n      <td>no trolly or staff to help you take the lugga...</td>\n      <td>1031471</td>\n    </tr>\n    <tr>\n      <th>1031472</th>\n      <td>0</td>\n      <td>The hotel looks like 3 but surely not 4</td>\n      <td>1031472</td>\n    </tr>\n    <tr>\n      <th>1031473</th>\n      <td>0</td>\n      <td>The ac was useless It was a hot week in vienn...</td>\n      <td>1031473</td>\n    </tr>\n    <tr>\n      <th>1031474</th>\n      <td>0</td>\n      <td>No Negative</td>\n      <td>1031474</td>\n    </tr>\n    <tr>\n      <th>1031475</th>\n      <td>0</td>\n      <td>I was in 3rd floor It didn t work Free Wife</td>\n      <td>1031475</td>\n    </tr>\n  </tbody>\n</table>\n<p>1031476 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Define a function to count the number of words in a string\ndef count_words(text):\n    return len(text.split())\n\ndf_train = df_train[df_train[\"Text\"].apply(lambda x: count_words(x) > 2)]\n\n# Randomly select one third of the rows with a seed\ndf_train = df_train.sample(frac=0.02, random_state=seed)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2023-04-09T08:22:10.408628Z","iopub.execute_input":"2023-04-09T08:22:10.409314Z","iopub.status.idle":"2023-04-09T08:22:12.062736Z","shell.execute_reply.started":"2023-04-09T08:22:10.409275Z","shell.execute_reply":"2023-04-09T08:22:12.061541Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"        Sentiment                                               Text      ID\n614439          0   the bed was huge but the mattress was not the...  614439\n270955          1   This was a nice older hotel in a residential ...  270955\n485273          1   large and quiet rooms king size beds smoking ...  485273\n567131          0   The water pressure was not good in the shower...  567131\n150214          1         Clean friendly and easy access to the tube  150214\n...           ...                                                ...     ...\n82181           1    Staff were fantastic Friendly and very helpful    82181\n486507          1     Breakfast selection and quality was excellent   486507\n407708          1   The staff were very helpful The roof terrace ...  407708\n406197          1   Beautiful hotel in great location close to ce...  406197\n490930          1   Bed was comfortable and room was quiet Staff ...  490930\n\n[15460 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentiment</th>\n      <th>Text</th>\n      <th>ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>614439</th>\n      <td>0</td>\n      <td>the bed was huge but the mattress was not the...</td>\n      <td>614439</td>\n    </tr>\n    <tr>\n      <th>270955</th>\n      <td>1</td>\n      <td>This was a nice older hotel in a residential ...</td>\n      <td>270955</td>\n    </tr>\n    <tr>\n      <th>485273</th>\n      <td>1</td>\n      <td>large and quiet rooms king size beds smoking ...</td>\n      <td>485273</td>\n    </tr>\n    <tr>\n      <th>567131</th>\n      <td>0</td>\n      <td>The water pressure was not good in the shower...</td>\n      <td>567131</td>\n    </tr>\n    <tr>\n      <th>150214</th>\n      <td>1</td>\n      <td>Clean friendly and easy access to the tube</td>\n      <td>150214</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>82181</th>\n      <td>1</td>\n      <td>Staff were fantastic Friendly and very helpful</td>\n      <td>82181</td>\n    </tr>\n    <tr>\n      <th>486507</th>\n      <td>1</td>\n      <td>Breakfast selection and quality was excellent</td>\n      <td>486507</td>\n    </tr>\n    <tr>\n      <th>407708</th>\n      <td>1</td>\n      <td>The staff were very helpful The roof terrace ...</td>\n      <td>407708</td>\n    </tr>\n    <tr>\n      <th>406197</th>\n      <td>1</td>\n      <td>Beautiful hotel in great location close to ce...</td>\n      <td>406197</td>\n    </tr>\n    <tr>\n      <th>490930</th>\n      <td>1</td>\n      <td>Bed was comfortable and room was quiet Staff ...</td>\n      <td>490930</td>\n    </tr>\n  </tbody>\n</table>\n<p>15460 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train.Text.apply(lambda x: len(x)).describe()","metadata":{"execution":{"iopub.status.busy":"2023-04-09T08:22:14.418543Z","iopub.execute_input":"2023-04-09T08:22:14.419014Z","iopub.status.idle":"2023-04-09T08:22:14.443205Z","shell.execute_reply.started":"2023-04-09T08:22:14.418976Z","shell.execute_reply":"2023-04-09T08:22:14.442297Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"count    15460.000000\nmean       121.938486\nstd        142.599095\nmin          8.000000\n25%         42.000000\n50%         78.000000\n75%        148.000000\nmax       1923.000000\nName: Text, dtype: float64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Multinomial Naive Bayes classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Defining input texts and labels\ntexts = df_train.Text\nlabels = df_train.Sentiment\n\n# Splitting the data into training and testing sets\ntext_train, text_test, label_train, label_test = train_test_split(texts, labels, test_size=0.2)\n\n# Creating bag of words features using CountVectorizer\nvectorizer = CountVectorizer()\nvectorizer.fit(text_train)\n\n# Converting text data into numerical features\ntrain_features = vectorizer.transform(text_train)\ntest_features = vectorizer.transform(text_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-08T14:32:11.490803Z","iopub.execute_input":"2023-04-08T14:32:11.491149Z","iopub.status.idle":"2023-04-08T14:32:12.201909Z","shell.execute_reply.started":"2023-04-08T14:32:11.491089Z","shell.execute_reply":"2023-04-08T14:32:12.200881Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter tuning\nparam_grid = {'alpha': [0.4, 0.6, 0.8, 1]}\n\nclassifier = MultinomialNB()\n\nclassifier_grid = GridSearchCV(estimator = classifier, param_grid = param_grid, cv = 5, scoring = 'accuracy')\nclassifier_grid.fit(train_features, label_train)\n\nclassifier_grid_results = pd.DataFrame(classifier_grid.cv_results_)\nclassifier_grid_results.sort_values(by = 'rank_test_score')","metadata":{"execution":{"iopub.status.busy":"2023-04-08T14:33:23.977432Z","iopub.execute_input":"2023-04-08T14:33:23.978392Z","iopub.status.idle":"2023-04-08T14:33:24.111224Z","shell.execute_reply.started":"2023-04-08T14:33:23.978340Z","shell.execute_reply":"2023-04-08T14:33:24.110044Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n3       0.004021      0.000127         0.000883        0.000100           1   \n0       0.004363      0.000564         0.000901        0.000070         0.4   \n1       0.003919      0.000045         0.000849        0.000051         0.6   \n2       0.003900      0.000033         0.000904        0.000068         0.8   \n\n           params  split0_test_score  split1_test_score  split2_test_score  \\\n3    {'alpha': 1}           0.926435           0.919968           0.921180   \n0  {'alpha': 0.4}           0.925627           0.921180           0.919159   \n1  {'alpha': 0.6}           0.926031           0.920372           0.918351   \n2  {'alpha': 0.8}           0.925627           0.919563           0.919159   \n\n   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n3           0.912657           0.916700         0.919388        0.004599   \n0           0.913870           0.916700         0.919307        0.003996   \n1           0.913465           0.916700         0.918984        0.004187   \n2           0.913061           0.917105         0.918903        0.004076   \n\n   rank_test_score  \n3                1  \n0                2  \n1                3  \n2                4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_alpha</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>0.004021</td>\n      <td>0.000127</td>\n      <td>0.000883</td>\n      <td>0.000100</td>\n      <td>1</td>\n      <td>{'alpha': 1}</td>\n      <td>0.926435</td>\n      <td>0.919968</td>\n      <td>0.921180</td>\n      <td>0.912657</td>\n      <td>0.916700</td>\n      <td>0.919388</td>\n      <td>0.004599</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.004363</td>\n      <td>0.000564</td>\n      <td>0.000901</td>\n      <td>0.000070</td>\n      <td>0.4</td>\n      <td>{'alpha': 0.4}</td>\n      <td>0.925627</td>\n      <td>0.921180</td>\n      <td>0.919159</td>\n      <td>0.913870</td>\n      <td>0.916700</td>\n      <td>0.919307</td>\n      <td>0.003996</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.003919</td>\n      <td>0.000045</td>\n      <td>0.000849</td>\n      <td>0.000051</td>\n      <td>0.6</td>\n      <td>{'alpha': 0.6}</td>\n      <td>0.926031</td>\n      <td>0.920372</td>\n      <td>0.918351</td>\n      <td>0.913465</td>\n      <td>0.916700</td>\n      <td>0.918984</td>\n      <td>0.004187</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.003900</td>\n      <td>0.000033</td>\n      <td>0.000904</td>\n      <td>0.000068</td>\n      <td>0.8</td>\n      <td>{'alpha': 0.8}</td>\n      <td>0.925627</td>\n      <td>0.919563</td>\n      <td>0.919159</td>\n      <td>0.913061</td>\n      <td>0.917105</td>\n      <td>0.918903</td>\n      <td>0.004076</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Training a Multinomial Naive Bayes classifier\nclassifier = MultinomialNB(alpha = 1)\nclassifier.fit(train_features, label_train)\n\n# Predicting the sentiment of test data\npredictions = classifier.predict(test_features)\n\n# Evaluating the accuracy of the model\naccuracy = classifier.score(test_features, label_test)\n\n# Printing model metrics\nprint(classification_report(label_test, predictions))\nprint(f\"Precision: {precision_score(label_test, predictions):.4f}\")\nprint(f\"Recall: {recall_score(label_test, predictions):.4f}\")\nprint(f\"F1: {f1_score(label_test, predictions):.4f}\")\nprint(f\"Accuracy: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-04-08T14:33:38.915103Z","iopub.execute_input":"2023-04-08T14:33:38.915786Z","iopub.status.idle":"2023-04-08T14:33:38.943469Z","shell.execute_reply.started":"2023-04-08T14:33:38.915751Z","shell.execute_reply":"2023-04-08T14:33:38.942367Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.91      0.91      0.91      1323\n           1       0.93      0.93      0.93      1769\n\n    accuracy                           0.92      3092\n   macro avg       0.92      0.92      0.92      3092\nweighted avg       0.92      0.92      0.92      3092\n\nPrecision: 0.9304\nRecall: 0.9293\nF1: 0.9299\nAccuracy: 0.9198\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# CatBoost","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.feature_extraction.text import CountVectorizer\ndata = df_train\n# Load data\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(data[\"Text\"], data[\"Sentiment\"], test_size=0.2, random_state=seed)\n\n# Convert text into numerical features using CountVectorizer\nvectorizer = CountVectorizer()\nX_train_counts = vectorizer.fit_transform(X_train)\nX_test_counts = vectorizer.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-08T15:17:22.620578Z","iopub.execute_input":"2023-04-08T15:17:22.621321Z","iopub.status.idle":"2023-04-08T15:17:22.911625Z","shell.execute_reply.started":"2023-04-08T15:17:22.621280Z","shell.execute_reply":"2023-04-08T15:17:22.910046Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter tuning\nparam_grid = {'depth': [4, 10],\n              'learning_rate': [0.05, 0.1],\n              'iterations': [500, 1000]}\n\nclassifier = CatBoostClassifier()\n\nclassifier_grid = GridSearchCV(estimator = classifier, param_grid = param_grid, cv = 5, scoring = 'accuracy')\nclassifier_grid.fit(X_train_counts, y_train, verbose=False)\n\nclassifier_grid_results = pd.DataFrame(classifier_grid.cv_results_)\nclassifier_grid_results.sort_values(by = 'rank_test_score')","metadata":{"execution":{"iopub.status.busy":"2023-04-08T15:17:24.764507Z","iopub.execute_input":"2023-04-08T15:17:24.765605Z","iopub.status.idle":"2023-04-08T16:24:37.774190Z","shell.execute_reply.started":"2023-04-08T15:17:24.765552Z","shell.execute_reply":"2023-04-08T16:24:37.773212Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_depth  \\\n7     229.558789      0.946895         0.046354        0.000706          10   \n6     230.076200      1.175251         0.045428        0.000625          10   \n5     115.006873      0.621157         0.045715        0.017247          10   \n3      20.055054      0.361829         0.040708        0.020005           4   \n4     115.091453      0.731781         0.036350        0.001090          10   \n2      20.186451      0.311159         0.025459        0.000261           4   \n1      10.157464      0.162407         0.030504        0.013754           4   \n0      10.582406      0.283809         0.030831        0.011924           4   \n\n  param_iterations param_learning_rate  \\\n7             1000                 0.1   \n6             1000                0.05   \n5              500                 0.1   \n3             1000                 0.1   \n4              500                0.05   \n2             1000                0.05   \n1              500                 0.1   \n0              500                0.05   \n\n                                              params  split0_test_score  \\\n7  {'depth': 10, 'iterations': 1000, 'learning_ra...           0.924414   \n6  {'depth': 10, 'iterations': 1000, 'learning_ra...           0.927243   \n5  {'depth': 10, 'iterations': 500, 'learning_rat...           0.923201   \n3  {'depth': 4, 'iterations': 1000, 'learning_rat...           0.924414   \n4  {'depth': 10, 'iterations': 500, 'learning_rat...           0.924818   \n2  {'depth': 4, 'iterations': 1000, 'learning_rat...           0.920372   \n1  {'depth': 4, 'iterations': 500, 'learning_rate...           0.917947   \n0  {'depth': 4, 'iterations': 500, 'learning_rate...           0.911479   \n\n   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n7           0.936944           0.924010           0.928427           0.934897   \n6           0.933711           0.930477           0.923979           0.932471   \n5           0.933711           0.927243           0.927618           0.932875   \n3           0.932094           0.929669           0.921957           0.932875   \n4           0.930073           0.926839           0.919531           0.930449   \n2           0.930073           0.926839           0.919127           0.928831   \n1           0.927243           0.926839           0.918722           0.929236   \n0           0.926031           0.919159           0.913870           0.921148   \n\n   mean_test_score  std_test_score  rank_test_score  \n7         0.929738        0.005318                1  \n6         0.929576        0.003551                2  \n5         0.928930        0.003894                3  \n3         0.928202        0.004301                4  \n4         0.926342        0.003994                5  \n2         0.925048        0.004465                6  \n1         0.923997        0.004701                7  \n0         0.918338        0.005191                8  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_depth</th>\n      <th>param_iterations</th>\n      <th>param_learning_rate</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>229.558789</td>\n      <td>0.946895</td>\n      <td>0.046354</td>\n      <td>0.000706</td>\n      <td>10</td>\n      <td>1000</td>\n      <td>0.1</td>\n      <td>{'depth': 10, 'iterations': 1000, 'learning_ra...</td>\n      <td>0.924414</td>\n      <td>0.936944</td>\n      <td>0.924010</td>\n      <td>0.928427</td>\n      <td>0.934897</td>\n      <td>0.929738</td>\n      <td>0.005318</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>230.076200</td>\n      <td>1.175251</td>\n      <td>0.045428</td>\n      <td>0.000625</td>\n      <td>10</td>\n      <td>1000</td>\n      <td>0.05</td>\n      <td>{'depth': 10, 'iterations': 1000, 'learning_ra...</td>\n      <td>0.927243</td>\n      <td>0.933711</td>\n      <td>0.930477</td>\n      <td>0.923979</td>\n      <td>0.932471</td>\n      <td>0.929576</td>\n      <td>0.003551</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>115.006873</td>\n      <td>0.621157</td>\n      <td>0.045715</td>\n      <td>0.017247</td>\n      <td>10</td>\n      <td>500</td>\n      <td>0.1</td>\n      <td>{'depth': 10, 'iterations': 500, 'learning_rat...</td>\n      <td>0.923201</td>\n      <td>0.933711</td>\n      <td>0.927243</td>\n      <td>0.927618</td>\n      <td>0.932875</td>\n      <td>0.928930</td>\n      <td>0.003894</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20.055054</td>\n      <td>0.361829</td>\n      <td>0.040708</td>\n      <td>0.020005</td>\n      <td>4</td>\n      <td>1000</td>\n      <td>0.1</td>\n      <td>{'depth': 4, 'iterations': 1000, 'learning_rat...</td>\n      <td>0.924414</td>\n      <td>0.932094</td>\n      <td>0.929669</td>\n      <td>0.921957</td>\n      <td>0.932875</td>\n      <td>0.928202</td>\n      <td>0.004301</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>115.091453</td>\n      <td>0.731781</td>\n      <td>0.036350</td>\n      <td>0.001090</td>\n      <td>10</td>\n      <td>500</td>\n      <td>0.05</td>\n      <td>{'depth': 10, 'iterations': 500, 'learning_rat...</td>\n      <td>0.924818</td>\n      <td>0.930073</td>\n      <td>0.926839</td>\n      <td>0.919531</td>\n      <td>0.930449</td>\n      <td>0.926342</td>\n      <td>0.003994</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20.186451</td>\n      <td>0.311159</td>\n      <td>0.025459</td>\n      <td>0.000261</td>\n      <td>4</td>\n      <td>1000</td>\n      <td>0.05</td>\n      <td>{'depth': 4, 'iterations': 1000, 'learning_rat...</td>\n      <td>0.920372</td>\n      <td>0.930073</td>\n      <td>0.926839</td>\n      <td>0.919127</td>\n      <td>0.928831</td>\n      <td>0.925048</td>\n      <td>0.004465</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.157464</td>\n      <td>0.162407</td>\n      <td>0.030504</td>\n      <td>0.013754</td>\n      <td>4</td>\n      <td>500</td>\n      <td>0.1</td>\n      <td>{'depth': 4, 'iterations': 500, 'learning_rate...</td>\n      <td>0.917947</td>\n      <td>0.927243</td>\n      <td>0.926839</td>\n      <td>0.918722</td>\n      <td>0.929236</td>\n      <td>0.923997</td>\n      <td>0.004701</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>10.582406</td>\n      <td>0.283809</td>\n      <td>0.030831</td>\n      <td>0.011924</td>\n      <td>4</td>\n      <td>500</td>\n      <td>0.05</td>\n      <td>{'depth': 4, 'iterations': 500, 'learning_rate...</td>\n      <td>0.911479</td>\n      <td>0.926031</td>\n      <td>0.919159</td>\n      <td>0.913870</td>\n      <td>0.921148</td>\n      <td>0.918338</td>\n      <td>0.005191</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Train CatBoost model\nmodel = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=10, loss_function='Logloss')\nmodel.fit(X_train_counts, y_train, verbose=False)\n\n# Predict sentiment on testing set\ny_pred = model.predict(X_test_counts)\n\n# Evaluate model accuracy\naccuracy = accuracy_score(y_test, y_pred)\n\n# Printing model metrics\nprint(classification_report(y_test, y_pred))\nprint(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\nprint(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\nprint(f\"F1: {f1_score(y_test, y_pred):.4f}\")\nprint(f\"Accuracy: {accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-08T16:25:36.709088Z","iopub.execute_input":"2023-04-08T16:25:36.709682Z","iopub.status.idle":"2023-04-08T16:30:19.716740Z","shell.execute_reply.started":"2023-04-08T16:25:36.709644Z","shell.execute_reply":"2023-04-08T16:30:19.715763Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.89      0.93      0.91      1341\n           1       0.95      0.91      0.93      1751\n\n    accuracy                           0.92      3092\n   macro avg       0.92      0.92      0.92      3092\nweighted avg       0.92      0.92      0.92      3092\n\nPrecision: 0.9467\nRecall: 0.9126\nF1: 0.9293\nAccuracy: 0.9214\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# LSTM","metadata":{}},{"cell_type":"code","source":"pip install keras_preprocessing","metadata":{"execution":{"iopub.status.busy":"2023-04-09T08:22:24.953181Z","iopub.execute_input":"2023-04-09T08:22:24.953772Z","iopub.status.idle":"2023-04-09T08:22:35.381407Z","shell.execute_reply.started":"2023-04-09T08:22:24.953734Z","shell.execute_reply":"2023-04-09T08:22:35.379748Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Collecting keras_preprocessing\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras_preprocessing) (1.21.6)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras_preprocessing) (1.16.0)\nInstalling collected packages: keras_preprocessing\nSuccessfully installed keras_preprocessing-1.1.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras_preprocessing.sequence import pad_sequences\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\nfrom keras.callbacks import EarlyStopping\nfrom keras.preprocessing.text import Tokenizer\nfrom sklearn.model_selection import train_test_split\nfrom keras_preprocessing.sequence import pad_sequences\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Load the dataset\n# The dataset should have two columns, one for the text and one for the label\ndataset = df_train\n\n# Preprocessing the text data\nmax_features = 5000\ntokenizer = Tokenizer(num_words=max_features, split=' ')\ntokenizer.fit_on_texts(dataset['Text'].values)\nX = tokenizer.texts_to_sequences(dataset['Text'].values)\nX = pad_sequences(X)\n\n# Splitting the dataset into training and testing sets\nY = dataset['Sentiment'].values\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n\n# Defining the model architecture\nembedding_dim = 32\nlstm_out = 49\nmodel = Sequential()\nmodel.add(Embedding(max_features, embedding_dim, input_length=X.shape[1]))\nmodel.add(SpatialDropout1D(0.4))\nmodel.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compiling the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Training the model\nepochs = 10\nbatch_size = 32\nearly_stop = EarlyStopping(monitor='val_loss', patience=2)\nmodel.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, verbose=2, validation_data=(X_test, Y_test), callbacks=[early_stop])\n\n# Predict sentiment on testing set\nY_pred = model.predict(X_test)\n\n# Evaluating the model on the test set\nscore, accuracy = model.evaluate(X_test, Y_test, verbose=0)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T08:22:50.633951Z","iopub.execute_input":"2023-04-09T08:22:50.634576Z","iopub.status.idle":"2023-04-09T09:35:38.288662Z","shell.execute_reply.started":"2023-04-09T08:22:50.634534Z","shell.execute_reply":"2023-04-09T09:35:38.287567Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/10\n387/387 - 653s - loss: 0.5242 - accuracy: 0.7983 - val_loss: 0.2166 - val_accuracy: 0.9269 - 653s/epoch - 2s/step\nEpoch 2/10\n387/387 - 621s - loss: 0.2424 - accuracy: 0.9169 - val_loss: 0.2834 - val_accuracy: 0.8984 - 621s/epoch - 2s/step\nEpoch 3/10\n387/387 - 611s - loss: 0.1844 - accuracy: 0.9375 - val_loss: 0.2095 - val_accuracy: 0.9266 - 611s/epoch - 2s/step\nEpoch 4/10\n387/387 - 611s - loss: 0.1487 - accuracy: 0.9510 - val_loss: 0.1621 - val_accuracy: 0.9447 - 611s/epoch - 2s/step\nEpoch 5/10\n387/387 - 605s - loss: 0.1314 - accuracy: 0.9567 - val_loss: 0.1615 - val_accuracy: 0.9424 - 605s/epoch - 2s/step\nEpoch 6/10\n387/387 - 616s - loss: 0.1139 - accuracy: 0.9641 - val_loss: 0.1640 - val_accuracy: 0.9424 - 616s/epoch - 2s/step\nEpoch 7/10\n387/387 - 620s - loss: 0.1086 - accuracy: 0.9639 - val_loss: 0.1707 - val_accuracy: 0.9392 - 620s/epoch - 2s/step\n97/97 [==============================] - 9s 90ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# Printing model metrics\nprint(classification_report(Y_test, Y_pred.round()))\nprint(f\"Precision: {precision_score(Y_test, Y_pred.round()):.4f}\")\nprint(f\"Recall: {recall_score(Y_test, Y_pred.round()):.4f}\")\nprint(f\"F1: {f1_score(Y_test, Y_pred.round()):.4f}\")\nprint(f\"Accuracy: {accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-09T09:35:38.291285Z","iopub.execute_input":"2023-04-09T09:35:38.291687Z","iopub.status.idle":"2023-04-09T09:35:38.315198Z","shell.execute_reply.started":"2023-04-09T09:35:38.291646Z","shell.execute_reply":"2023-04-09T09:35:38.314127Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.93      0.93      0.93      1354\n           1       0.95      0.95      0.95      1738\n\n    accuracy                           0.94      3092\n   macro avg       0.94      0.94      0.94      3092\nweighted avg       0.94      0.94      0.94      3092\n\nPrecision: 0.9454\nRecall: 0.9465\nF1: 0.9459\nAccuracy: 0.9392\n","output_type":"stream"}]}]}